---
title: "ETFproject"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## scrape online text we'll make use of the relatively newer rvest

```{r cars}
library(rvest)
Sys.setenv(http_proxy="http://dia2.santanderuk.gs.corp:80")
Sys.getenv("http_proxy")

rvestx <- read_html("http://etfdb.com/type/sector/all/#etfs__overview&sort_name=assets_under_management&sort_order=desc&page=1")

grepl('VNQ', x, ignore.case=F)

posfirst = regexpr('VNQ', x) -100  # Returns position of 1st match in a string
poslast = regexpr('VNQ', x) + 100

substr(x, posfirst, poslast)


rvestx %>% html_node("tbody" ) %>% html_node(" tr" )   %>% html_node("td" )  %>% html_node("a" )    %>% html_text() 

#So, this package only works for static web page,  ...  ?

x %>% html_node(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "caps", " " ))]') %>% html_text()



```

## dinamic websites

lets gather the website as html throuth jsp 

#scrape_techstars.js

#https://www.datacamp.com/community/tutorials/scraping-javascript-generated-data-with-r#gs.er=B0wg

```{js  pressure, echo=FALSE}


http://phantomjs.org/download.html


var webPage = require('webpage');
var page = webPage.create();

var fs = require('fs');
var path = 'techstars.html'

page.open('http://www.techstars.com/companies/stats/', function (status) {
  var content = page.content;
  fs.write(path,content,'w')
  phantom.exit();
});

```


now that we have the html is easier scrap it. 


```{r pressure, echo=FALSE}
xlocal <- read_html("C:/HIP/SOFT/instalados/phantomjs-2.1.1-windows/bin/etf.html")


x %>% html_node("#etfs :nth-child(1)") %>% html_text()


x %>% html_node("tbody" ) %>% html_node(" tr" )   %>% html_node("td" )  %>% html_node("a" )    %>% html_text() 

 
x %>% html_node(xpath='//a') %>% html_text()


x %>% html_node(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "caps", " " ))]') %>% html_text()

xlocal %>% html_node("bootstrap-table") %>%    html_table(header = TRUE)


```

althought as we already have the information we probably should focus in how to parse the XML

```{r pressure, echo=FALSE}
library(XML)
xlocalt <- read_html("C:/HIP/SOFT/instalados/phantomjs-2.1.1-windows/bin/etf.html")
 getNodeSet(xlocalt,'//*/book')


```


Hassle-free HTML tables with htmltab

```{r pressure, echo=FALSE}
#https://cran.r-project.org/web/packages/htmltab/vignettes/htmltab.html
library(htmltab)

install.packages("htmltab")


url <- "http://christianrubba.com/cran/htmltab/vignette/Demography%20of%20the%20United%20Kingdom%20-%20Wikipedia.html"
ukLang <- htmltab(doc = url, which = "//th[text() = 'Ability']/ancestor::table")
head(ukLang)

xlocal <- read_html("C:/HIP/SOFT/instalados/phantomjs-2.1.1-windows/bin/etf.html")
ukLang <- htmltab(doc = url, which = "//tr[text() = 'Symbol']")
```




## yahoo data -----
```{r yahoo, echo=FALSE}
TES = c("CHOC")
data.source = c("yahoo")

library(quantmod, warn.conflicts = FALSE, quietly = TRUE)
library(PerformanceAnalytics, warn.conflicts = FALSE, quietly = TRUE)
library(knitr, warn.conflicts = FALSE, quietly = TRUE)

TES = c("CHOC")
data.source = c("yahoo")
suppressWarnings(getData(TES, data.source))


getData<-function(tickers,datasrc){
  for (i in 1:length(tickers)){
    cat(tickers[i],i,"\n")
    getSymbols(tickers[i],src=datasrc,
               auto.assign=getOption("getSymbols.auto.assign",TRUE),
               env=parent.frame())
  }
}

```



